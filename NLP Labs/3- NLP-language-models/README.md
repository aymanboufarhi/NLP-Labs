# Lab : Get familiar with with NLP language models using Sklearn library

Lab : Get familiar with with NLP language models using Sklearn library

Tools : Google colab, github, NLTK, Sklearn.

## Table of contents
 - [Introduction](https://github.com/aymanboufarhi/NLP-language-models?tab=readme-ov-file#introduction)
 - [Preprocessing Pipeline](https://github.com/aymanboufarhi/NLP-language-models?tab=readme-ov-file#data-acquisition)
 - [Encoding Data Vectors](https://github.com/aymanboufarhi/NLP-language-models?tab=readme-ov-file#encoding-data-vectors)
 - [Regression Modeling](https://github.com/aymanboufarhi/NLP-language-models?tab=readme-ov-file#regression-modeling)
 - [Classification Modeling](https://github.com/aymanboufarhi/NLP-language-models?tab=readme-ov-file#classification-modeling)
 - [Synthesis](https://github.com/aymanboufarhi/NLP-language-models?tab=readme-ov-file#synthesis)

## Introduction
Throughout this lab, I've delved into the intricate world of Natural Language Processing (NLP) using the Scikit-learn library, unraveling the complexities of processing, modeling, and understanding textual data. Here's a comprehensive synthesis of my journey :

## Preprocessing Pipeline
I initiated my exploration by establishing a robust preprocessing pipeline, recognizing its pivotal role in any NLP task. Through tokenization, stemming, lemmatization, and stop word removal, I meticulously prepared my textual data, ensuring it was cleansed and standardized for subsequent analysis. This step laid the groundwork for extracting meaningful insights from raw text.

## Encoding Data Vectors
Diving deeper, I ventured into the realm of encoding text data into numerical vectors, a pivotal transformation enabling machines to comprehend and analyze textual information effectively. I explored various encoding techniques, from the traditional Bag of Words and TF-IDF to the more sophisticated Word2Vec embeddings. Each method encapsulated the essence of textual data in numerical form, facilitating further processing and modeling.

## Regression Modeling
Embarking on my regression journey, I trained a spectrum of models—SVR, Linear Regression, and Decision Tree—to predict numerical values based on the embeddings derived from my text data. Armed with evaluation metrics such as Mean Squared Error (MSE) and Root Mean Squared Error (RMSE), I meticulously assessed the performance of each model, deciphering their capabilities and limitations in capturing the underlying patterns within the textual data.

## Classification Modeling
Shifting gears, I traversed the landscape of classification modeling, where the task was to classify sentiment based on text data embeddings. Armed with a diverse ensemble of classifiers—SVM, Naive Bayes, Logistic Regression, and AdaBoost—I embarked on a quest to decipher the sentiment encoded within textual narratives. Through an array of evaluation metrics including accuracy, F1 score, precision, and recall, I meticulously scrutinized the efficacy of each classifier, unraveling their strengths and weaknesses in discerning sentiment nuances.

## Interpreting Results
With results in hand, I embarked on the pivotal journey of interpretation, deciphering the implications of model performance metrics and unraveling the narratives hidden within the numerical outputs. From discerning the significance of MSE and RMSE in regression tasks to dissecting the precision and recall trade-offs in classification endeavors, I meticulously dissected the intricacies of model performance, extracting actionable insights and informing subsequent decision-making processes.

## Synthesis
As my journey culminates, I stand at the precipice of a profound synthesis—a synthesis that transcends mere technical proficiency and delves into the realm of conceptual understanding. Through the crucible of this lab, I've not only acquired practical skills in NLP using Scikit-learn but also cultivated a deep-seated appreciation for the intricate dance between human language and machine intelligence. Armed with a holistic understanding of preprocessing, encoding, modeling, and interpretation, I emerge as a proficient navigator of the NLP landscape, equipped to tackle real-world challenges and embark on transformative journeys fueled by the power of language and computation.
